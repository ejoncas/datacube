<?xml version="1.0" encoding="UTF-8" standalone="no"?><configuration>
<property><name>job.end.retry.interval</name><value>30000</value></property>
<property><name>io.bytes.per.checksum</name><value>512</value></property>
<property><name>mapred.job.tracker.retiredjobs.cache.size</name><value>1000</value></property>
<property><name>mapred.queue.default.acl-administer-jobs</name><value>*</value></property>
<property><name>hbase.regions.slop</name><value>0.2</value></property>
<property><name>mapred.task.profile.reduces</name><value>0-2</value></property>
<property><name>mapreduce.job.cache.files.visibilities</name><value>true</value></property>
<property><name>mapreduce.jobtracker.staging.root.dir</name><value>${hadoop.tmp.dir}/mapred/staging</value></property>
<property><name>hbase.zookeeper.leaderport</name><value>3888</value></property>
<property><name>hbase.regionserver.info.port</name><value>60030</value></property>
<property><name>mapred.job.reuse.jvm.num.tasks</name><value>1</value></property>
<property><name>dfs.block.access.token.lifetime</name><value>600</value></property>
<property><name>mapred.reduce.tasks.speculative.execution</name><value>false</value></property>
<property><name>dfs.datanode.artificialBlockReceivedDelay</name><value>5</value></property>
<property><name>hbase.rs.cacheblocksonwrite</name><value>false</value></property>
<property><name>mapred.job.name</name><value>DataCube HBase snapshotter</value></property>
<property><name>dfs.permissions.supergroup</name><value>supergroup</value></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value></property>
<property><name>mapreduce.partitioner.class</name><value>org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner</value></property>
<property><name>hbase.data.umask.enable</name><value>false</value></property>
<property><name>hbase.master.dns.nameserver</name><value>default</value></property>
<property><name>mapred.task.tracker.http.address</name><value>0.0.0.0:50060</value></property>
<property><name>dfs.namenode.delegation.token.renew-interval</name><value>86400000</value></property>
<property><name>mapred.cache.archives.timestamps</name><value>1400700919905,1400700920351,1400700920410,1400700920861</value></property>
<property><name>hfile.format.version</name><value>2</value></property>
<property><name>hbase.auth.token.max.lifetime</name><value>604800000</value></property>
<property><name>fs.ramfs.impl</name><value>org.apache.hadoop.fs.InMemoryFileSystem</value></property>
<property><name>mapred.system.dir</name><value>${hadoop.tmp.dir}/mapred/system</value></property>
<property><name>mapred.task.tracker.report.address</name><value>127.0.0.1:0</value></property>
<property><name>mapreduce.reduce.shuffle.connect.timeout</name><value>180000</value></property>
<property><name>mapred.healthChecker.interval</name><value>60000</value></property>
<property><name>hbase.hregion.memstore.flush.size</name><value>134217728</value></property>
<property><name>mapreduce.job.complete.cancel.delegation.tokens</name><value>true</value></property>
<property><name>hbase.regionserver.logroll.period</name><value>3600000</value></property>
<property><name>fs.trash.interval</name><value>0</value></property>
<property><name>mapred.skip.map.auto.incr.proc.count</name><value>true</value></property>
<property><name>mapred.child.tmp</name><value>./tmp</value></property>
<property><name>hbase.hfileoutputformat.families.compression</name><value>c=none</value></property>
<property><name>hbase.regionserver.dns.interface</name><value>default</value></property>
<property><name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name><value>5000</value></property>
<property><name>dfs.datanode.http.address</name><value>127.0.0.1:0</value></property>
<property><name>tmpjars</name><value>file:/home/charly/.m2/repository/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar,file:/home/charly/.m2/repository/org/apache/hbase/hbase/0.94.0/hbase-0.94.0.jar,file:/home/charly/.m2/repository/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar,file:/home/charly/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar</value></property>
<property><name>hbase.hstore.blockingStoreFiles</name><value>7</value></property>
<property><name>io.sort.spill.percent</name><value>0.80</value></property>
<property><name>hbase.rpc.engine</name><value>org.apache.hadoop.hbase.ipc.WritableRpcEngine</value></property>
<property><name>mapred.job.shuffle.input.buffer.percent</name><value>0.70</value></property>
<property><name>dfs.max.objects</name><value>0</value></property>
<property><name>hbase.client.write.buffer</name><value>2097152</value></property>
<property><name>mapred.skip.map.max.skip.records</name><value>0</value></property>
<property><name>mapreduce.reduce.shuffle.maxfetchfailures</name><value>10</value></property>
<property><name>hadoop.security.authorization</name><value>false</value></property>
<property><name>hbase.zookeeper.property.clientPort</name><value>56445</value></property>
<property><name>hbase.regionserver.info.port.auto</name><value>false</value></property>
<property><name>mapred.task.profile.maps</name><value>0-2</value></property>
<property><name>dfs.https.server.keystore.resource</name><value>ssl-server.xml</value></property>
<property><name>dfs.replication.interval</name><value>3</value></property>
<property><name>mapred.local.dir</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/mapred-local-dir</value></property>
<property><name>mapred.merge.recordsBeforeProgress</name><value>10000</value></property>
<property><name>mapred.job.tracker.http.address</name><value>0.0.0.0:50030</value></property>
<property><name>hbase.master.logcleaner.ttl</name><value>600000</value></property>
<property><name>mapred.compress.map.output</name><value>false</value></property>
<property><name>mapred.userlog.retain.hours</name><value>24</value></property>
<property><name>hbase.regionserver.optionallogflushinterval</name><value>1000</value></property>
<property><name>mapred.create.symlink</name><value>yes</value></property>
<property><name>mapred.tasktracker.reduce.tasks.maximum</name><value>2</value></property>
<property><name>hadoop.security.uid.cache.secs</name><value>14400</value></property>
<property><name>hbase.rootdir</name><value>hdfs://localhost:51932/user/charly/hbase</value></property>
<property><name>fs.har.impl.disable.cache</name><value>true</value></property>
<property><name>mapred.cluster.map.memory.mb</name><value>-1</value></property>
<property><name>hbase.zookeeper.dns.interface</name><value>default</value></property>
<property><name>zookeeper.session.timeout</name><value>180000</value></property>
<property><name>dfs.data.dir</name><value>${hadoop.tmp.dir}/dfs/data</value></property>
<property><name>hbase.mapreduce.hfileoutputformat.blocksize</name><value>65536</value></property>
<property><name>dfs.access.time.precision</name><value>3600000</value></property>
<property><name>hbase.hstore.compaction.max</name><value>10</value></property>
<property><name>dfs.replication.min</name><value>1</value></property>
<property><name>mapreduce.job.submithost</name><value>heisenberg</value></property>
<property><name>fs.checkpoint.dir</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/dfscluster_aad504e8-cd3f-411c-aea3-9b5473a19e07/dfs/namesecondary1,/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/dfscluster_aad504e8-cd3f-411c-aea3-9b5473a19e07/dfs/namesecondary2</value></property>
<property><name>fs.s3n.impl</name><value>org.apache.hadoop.fs.s3native.NativeS3FileSystem</value></property>
<property><name>mapreduce.tasktracker.outofband.heartbeat</name><value>false</value></property>
<property><name>hbase.master.info.bindAddress</name><value>0.0.0.0</value></property>
<property><name>mapreduce.tasktracker.outofband.heartbeat.damper</name><value>1000000</value></property>
<property><name>mapred.jobtracker.restart.recover</name><value>false</value></property>
<property><name>hbase.hstore.compactionThreshold</name><value>3</value></property>
<property><name>io.storefile.bloom.block.size</name><value>131072</value></property>
<property><name>hadoop.logfile.size</name><value>10000000</value></property>
<property><name>mapreduce.job.cache.archives.visibilities</name><value>false,false,false,false</value></property>
<property><name>hbase.offheapcache.percentage</name><value>0</value></property>
<property><name>hbase.regionserver.nbreservationblocks</name><value>4</value></property>
<property><name>hbase.thrift.maxQueuedRequests</name><value>1000</value></property>
<property><name>dfs.support.append</name><value>true</value></property>
<property><name>hbase.thrift.minWorkerThreads</name><value>16</value></property>
<property><name>hadoop.security.token.service.use_ip</name><value>true</value></property>
<property><name>mapred.inmem.merge.threshold</name><value>1000</value></property>
<property><name>ipc.client.connection.maxidletime</name><value>10000</value></property>
<property><name>fs.checkpoint.size</name><value>67108864</value></property>
<property><name>hbase.data.umask</name><value>000</value></property>
<property><name>dfs.blockreport.intervalMsec</name><value>3600000</value></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value></property>
<property><name>dfs.client.block.write.retries</name><value>3</value></property>
<property><name>hbase.balancer.period</name><value>300000</value></property>
<property><name>mapred.reduce.tasks</name><value>1</value></property>
<property><name>mapred.queue.names</name><value>default</value></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value></property>
<property><name>hbase.zookeeper.property.maxClientCnxns</name><value>300</value></property>
<property><name>dfs.https.enable</name><value>false</value></property>
<property><name>hbase.master.wait.on.regionservers.mintostart</name><value>1</value></property>
<property><name>dfs.replication</name><value>1</value></property>
<property><name>mapred.jobtracker.blacklist.fault-timeout-window</name><value>180</value></property>
<property><name>ipc.client.tcpnodelay</name><value>false</value></property>
<property><name>hbase.client.scanner.caching</name><value>1</value></property>
<property><name>mapred.acls.enabled</name><value>false</value></property>
<property><name>mapred.tasktracker.dns.nameserver</name><value>default</value></property>
<property><name>mapred.submit.replication</name><value>10</value></property>
<property><name>hbase.client.retries.number</name><value>10</value></property>
<property><name>mapred.cache.archives.filesizes</name><value>767592,4541341,449818,3928347</value></property>
<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</value></property>
<property><name>io.file.buffer.size</name><value>4096</value></property>
<property><name>hbase.zookeeper.dns.nameserver</name><value>default</value></property>
<property><name>hfile.index.block.max.size</name><value>131072</value></property>
<property><name>hbase.regionserver.hlog.reader.impl</name><value>org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader</value></property>
<property><name>mapred.map.tasks.speculative.execution</name><value>false</value></property>
<property><name>hbase.zookeeper.property.dataDir</name><value>${hbase.tmp.dir}/zookeeper</value></property>
<property><name>hbase.hregion.memstore.mslab.enabled</name><value>true</value></property>
<property><name>hbase.regionserver.dns.nameserver</name><value>default</value></property>
<property><name>mapreduce.job.split.metainfo.maxsize</name><value>10000000</value></property>
<property><name>hfile.block.index.cacheonwrite</name><value>false</value></property>
<property><name>mapred.map.max.attempts</name><value>4</value></property>
<property><name>hfile.block.cache.size</name><value>0.25</value></property>
<property><name>mapred.job.shuffle.merge.percent</name><value>0.66</value></property>
<property><name>fs.har.impl</name><value>org.apache.hadoop.fs.HarFileSystem</value></property>
<property><name>hbase.regionserver.class</name><value>org.apache.hadoop.hbase.ipc.HRegionInterface</value></property>
<property><name>hadoop.security.authentication</name><value>simple</value></property>
<property><name>fs.s3.buffer.dir</name><value>${hadoop.tmp.dir}/s3</value></property>
<property><name>mapred.skip.reduce.auto.incr.proc.count</name><value>true</value></property>
<property><name>dfs.http.address</name><value>localhost:39543</value></property>
<property><name>hbase.master.info.port</name><value>60010</value></property>
<property><name>mapred.job.classpath.archives</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/zookeeper-3.4.3.jar:/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/hbase-0.94.0.jar:/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/protobuf-java-2.4.0a.jar:/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/hadoop-core-1.0.3.jar</value></property>
<property><name>mapred.job.tracker.jobhistory.lru.cache.size</name><value>5</value></property>
<property><name>mapreduce.outputformat.class</name><value>org.apache.hadoop.hbase.mapreduce.HFileOutputFormat</value></property>
<property><name>dfs.replication.considerLoad</name><value>true</value></property>
<property><name>mapred.jobtracker.blacklist.fault-bucket-width</name><value>15</value></property>
<property><name>dfs.block.access.token.enable</name><value>false</value></property>
<property><name>mapreduce.job.acl-view-job</name><value> </value></property>
<property><name>hbase.mapreduce.inputtable</name><value>cube_data</value></property>
<property><name>mapred.job.queue.name</name><value>default</value></property>
<property><name>hadoop.policy.file</name><value>hbase-policy.xml</value></property>
<property><name>dfs.permissions</name><value>true</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.hours</name><value>0</value></property>
<property><name>fs.file.impl</name><value>org.apache.hadoop.fs.LocalFileSystem</value></property>
<property><name>dfs.block.size</name><value>67108864</value></property>
<property><name>hbase.hash.type</name><value>murmur</value></property>
<property><name>dfs.https.address</name><value>0.0.0.0:50470</value></property>
<property><name>ipc.client.kill.max</name><value>10</value></property>
<property><name>mapred.healthChecker.script.timeout</name><value>600000</value></property>
<property><name>mapred.tasktracker.map.tasks.maximum</name><value>2</value></property>
<property><name>zookeeper.znode.acl.parent</name><value>acl</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.dir</name><value>/jobtracker/jobsInfo</value></property>
<property><name>dfs.default.chunk.view.size</name><value>32768</value></property>
<property><name>hbase.auth.key.update.interval</name><value>86400000</value></property>
<property><name>mapred.reduce.slowstart.completed.maps</name><value>0.05</value></property>
<property><name>mapreduce.reduce.class</name><value>org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer</value></property>
<property><name>io.sort.mb</name><value>100</value></property>
<property><name>dfs.datanode.failed.volumes.tolerated</name><value>0</value></property>
<property><name>dfs.https.need.client.auth</name><value>false</value></property>
<property><name>hbase.regionserver.regionSplitLimit</name><value>2147483647</value></property>
<property><name>hbase.rest.port</name><value>8080</value></property>
<property><name>mapreduce.inputformat.class</name><value>org.apache.hadoop.hbase.mapreduce.TableInputFormat</value></property>
<property><name>dfs.datanode.data.dir.perm</name><value>755</value></property>
<property><name>ipc.server.listen.queue.size</name><value>128</value></property>
<property><name>io.mapfile.bloom.size</name><value>1048576</value></property>
<property><name>fs.hsftp.impl</name><value>org.apache.hadoop.hdfs.HsftpFileSystem</value></property>
<property><name>mapred.cache.files.timestamps</name><value>1400700919369</value></property>
<property><name>mapred.combine.recordsBeforeProgress</name><value>10000</value></property>
<property><name>dfs.datanode.dns.nameserver</name><value>default</value></property>
<property><name>hbase.client.pause</name><value>1000</value></property>
<property><name>mapred.child.java.opts</name><value>-Xmx200m</value></property>
<property><name>dfs.replication.max</name><value>512</value></property>
<property><name>mapred.queue.default.state</name><value>RUNNING</value></property>
<property><name>map.sort.class</name><value>org.apache.hadoop.util.QuickSort</value></property>
<property><name>hbase.mapreduce.scan</name><value>AgAAAAAAAf////8AABOIAQAAAAAAAAAAAH//////////AQAAAAEBYwAAAAAAAAAA</value></property>
<property><name>hadoop.util.hash.type</name><value>murmur</value></property>
<property><name>topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.StaticMapping</value></property>
<property><name>dfs.block.access.key.update.interval</name><value>600</value></property>
<property><name>dfs.datanode.dns.interface</name><value>default</value></property>
<property><name>mapred.output.compression.type</name><value>RECORD</value></property>
<property><name>mapred.reducer.new-api</name><value>true</value></property>
<property><name>mapred.skip.attempts.to.start.skipping</name><value>2</value></property>
<property><name>mapreduce.job.dir</name><value>hdfs://localhost:51932/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005</value></property>
<property><name>io.map.index.skip</name><value>0</value></property>
<property><name>hadoop.log.dir</name><value>/tmp/datacube_hadoop_logs</value></property>
<property><name>mapred.cluster.max.map.memory.mb</name><value>-1</value></property>
<property><name>fs.s3.maxRetries</name><value>4</value></property>
<property><name>dfs.namenode.logging.level</name><value>info</value></property>
<property><name>mapred.task.tracker.task-controller</name><value>org.apache.hadoop.mapred.DefaultTaskController</value></property>
<property><name>mapred.userlog.limit.kb</name><value>0</value></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value></property>
<property><name>fs.hftp.impl</name><value>org.apache.hadoop.hdfs.HftpFileSystem</value></property>
<property><name>hbase.hstore.blockingWaitTime</name><value>90000</value></property>
<property><name>dfs.namenode.handler.count</name><value>10</value></property>
<property><name>fs.kfs.impl</name><value>org.apache.hadoop.fs.kfs.KosmosFileSystem</value></property>
<property><name>mapreduce.job.submithostaddress</name><value>127.0.0.1</value></property>
<property><name>mapred.map.tasks</name><value>1</value></property>
<property><name>mapred.local.dir.minspacekill</name><value>0</value></property>
<property><name>fs.hdfs.impl</name><value>org.apache.hadoop.hdfs.DistributedFileSystem</value></property>
<property><name>hbase.coprocessor.abortonerror</name><value>false</value></property>
<property><name>mapred.job.map.memory.mb</name><value>-1</value></property>
<property><name>mapred.jobtracker.completeuserjobs.maximum</name><value>100</value></property>
<property><name>io.storefile.bloom.cacheonwrite</name><value>false</value></property>
<property><name>hbase.zookeeper.quorum</name><value>localhost</value></property>
<property><name>hbase.defaults.for.version</name><value>0.94.0</value></property>
<property><name>hbase.hregion.max.filesize</name><value>10737418240</value></property>
<property><name>hbase.regionserver.logroll.errors.tolerated</name><value>2</value></property>
<property><name>zookeeper.znode.parent</name><value>/hbase</value></property>
<property><name>dfs.blockreport.initialDelay</name><value>0</value></property>
<property><name>mapred.min.split.size</name><value>0</value></property>
<property><name>dfs.namenode.delegation.token.max-lifetime</name><value>604800000</value></property>
<property><name>fs.ftp.impl</name><value>org.apache.hadoop.fs.ftp.FTPFileSystem</value></property>
<property><name>dfs.secondary.http.address</name><value>0.0.0.0:50090</value></property>
<property><name>mapred.output.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value></property>
<property><name>mapred.cache.files</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/mapred-working-dir/partitions_02d4492a-1e88-466e-be59-a72fedaed0b4#_partition.lst</value></property>
<property><name>hbase.metrics.showTableName</name><value>true</value></property>
<property><name>mapred.cluster.max.reduce.memory.mb</name><value>-1</value></property>
<property><name>mapred.cluster.reduce.memory.mb</name><value>-1</value></property>
<property><name>hbase.regionserver.hlog.writer.impl</name><value>org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter</value></property>
<property><name>dfs.web.ugi</name><value>webuser,webgroup</value></property>
<property><name>mapred.task.profile</name><value>false</value></property>
<property><name>mapred.reduce.parallel.copies</name><value>5</value></property>
<property><name>hbase.master.wait.on.regionservers.maxtostart</name><value>1</value></property>
<property><name>dfs.heartbeat.interval</name><value>3</value></property>
<property><name>hbase.zookeeper.property.syncLimit</name><value>5</value></property>
<property><name>hbase.regionserver.lease.period</name><value>60000</value></property>
<property><name>local.cache.size</name><value>10737418240</value></property>
<property><name>hbase.regionserver.msginterval</name><value>3000</value></property>
<property><name>zookeeper.znode.rootserver</name><value>root-region-server</value></property>
<property><name>io.sort.factor</name><value>10</value></property>
<property><name>mapreduce.map.class</name><value>com.urbanairship.datacube.backfill.HBaseSnapshotter$ResultToKvsMapper</value></property>
<property><name>mapred.task.timeout</name><value>600000</value></property>
<property><name>dfs.safemode.extension</name><value>0</value></property>
<property><name>hbase.master.logcleaner.plugins</name><value>org.apache.hadoop.hbase.master.TimeToLiveLogCleaner</value></property>
<property><name>mapreduce.framework.name</name><value>yarn</value></property>
<property><name>ipc.client.idlethreshold</name><value>4000</value></property>
<property><name>slave.host.name</name><value>127.0.0.1</value></property>
<property><name>ipc.server.tcpnodelay</name><value>false</value></property>
<property><name>hadoop.logfile.count</name><value>10</value></property>
<property><name>mapred.output.dir</name><value>hdfs:/test_hfiles</value></property>
<property><name>mapred.heartbeats.in.second</name><value>100</value></property>
<property><name>hbase.online.schema.update.enable</name><value>false</value></property>
<property><name>fs.s3.block.size</name><value>67108864</value></property>
<property><name>mapred.map.output.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value></property>
<property><name>mapred.task.cache.levels</name><value>2</value></property>
<property><name>mapred.tasktracker.dns.interface</name><value>default</value></property>
<property><name>mapred.output.key.class</name><value>org.apache.hadoop.hbase.io.ImmutableBytesWritable</value></property>
<property><name>fs.defaultFS</name><value>hdfs://localhost:51932</value></property>
<property><name>mapred.job.reduce.memory.mb</name><value>-1</value></property>
<property><name>hbase.tmp.dir</name><value>/tmp/hbase-${user.name}</value></property>
<property><name>hbase.zookeeper.property.initLimit</name><value>10</value></property>
<property><name>mapred.mapoutput.value.class</name><value>org.apache.hadoop.hbase.KeyValue</value></property>
<property><name>mapred.max.tracker.failures</name><value>4</value></property>
<property><name>hbase.cluster.distributed</name><value>false</value></property>
<property><name>dfs.df.interval</name><value>60000</value></property>
<property><name>hbase.thrift.maxWorkerThreads</name><value>1000</value></property>
<property><name>mapreduce.reduce.shuffle.read.timeout</name><value>180000</value></property>
<property><name>mapred.tasktracker.tasks.sleeptime-before-sigkill</name><value>5000</value></property>
<property><name>mapred.cache.archives</name><value>hdfs://localhost:51932/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/zookeeper-3.4.3.jar,hdfs://localhost:51932/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/hbase-0.94.0.jar,hdfs://localhost:51932/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/protobuf-java-2.4.0a.jar,hdfs://localhost:51932/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir/mapred/staging/charly/.staging/job_20140521163156863_0005/libjars/hadoop-core-1.0.3.jar</value></property>
<property><name>mapred.max.tracker.blacklists</name><value>4</value></property>
<property><name>jobclient.output.filter</name><value>FAILED</value></property>
<property><name>hbase.bulkload.retries.number</name><value>0</value></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization</value></property>
<property><name>hbase.rest.readonly</name><value>false</value></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value></property>
<property><name>mapred.jobtracker.taskScheduler</name><value>org.apache.hadoop.mapred.JobQueueTaskScheduler</value></property>
<property><name>job.end.retry.attempts</name><value>0</value></property>
<property><name>ipc.client.connect.max.retries</name><value>10</value></property>
<property><name>dfs.namenode.delegation.key.update-interval</name><value>86400000</value></property>
<property><name>hbase.regionserver.port</name><value>60020</value></property>
<property><name>webinterface.private.actions</name><value>false</value></property>
<property><name>mapred.tasktracker.indexcache.mb</name><value>10</value></property>
<property><name>hbase.regionserver.handler.count</name><value>10</value></property>
<property><name>fs.checkpoint.edits.dir</name><value>${fs.checkpoint.dir}</value></property>
<property><name>mapreduce.reduce.input.limit</name><value>-1</value></property>
<property><name>mapred.output.value.class</name><value>org.apache.hadoop.hbase.KeyValue</value></property>
<property><name>hbase.hregion.majorcompaction</name><value>86400000</value></property>
<property><name>mapred.mapper.new-api</name><value>true</value></property>
<property><name>tasktracker.http.threads</name><value>40</value></property>
<property><name>mapred.job.tracker.handler.count</name><value>10</value></property>
<property><name>keep.failed.task.files</name><value>false</value></property>
<property><name>mapred.output.compress</name><value>false</value></property>
<property><name>hadoop.security.group.mapping</name><value>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</value></property>
<property><name>mapred.cache.files.filesizes</name><value>153</value></property>
<property><name>dfs.https.client.keystore.resource</name><value>ssl-client.xml</value></property>
<property><name>mapred.jobtracker.job.history.block.size</name><value>3145728</value></property>
<property><name>mapred.skip.reduce.max.skip.groups</name><value>0</value></property>
<property><name>dfs.datanode.address</name><value>127.0.0.1:0</value></property>
<property><name>dfs.datanode.https.address</name><value>0.0.0.0:50475</value></property>
<property><name>fs.s3.impl</name><value>org.apache.hadoop.fs.s3.S3FileSystem</value></property>
<property><name>hbase.regionserver.global.memstore.upperLimit</name><value>0.4</value></property>
<property><name>hadoop.tmp.dir</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/hadoop-tmp-dir</value></property>
<property><name>mapred.line.input.format.linespermap</name><value>1</value></property>
<property><name>hbase.regionserver.global.memstore.lowerLimit</name><value>0.35</value></property>
<property><name>hbase.hregion.preclose.flush.size</name><value>5242880</value></property>
<property><name>dfs.datanode.du.reserved</name><value>0</value></property>
<property><name>topology.script.number.args</name><value>100</value></property>
<property><name>fs.default.name</name><value>hdfs://localhost:51932</value></property>
<property><name>dfs.balance.bandwidthPerSec</name><value>1048576</value></property>
<property><name>hbase.master.dns.interface</name><value>default</value></property>
<property><name>mapred.local.dir.minspacestart</name><value>0</value></property>
<property><name>mapred.jobtracker.maxtasks.per.job</name><value>-1</value></property>
<property><name>dfs.namenode.startup</name><value>REGULAR</value></property>
<property><name>mapred.user.jobconf.limit</name><value>5242880</value></property>
<property><name>mapred.reduce.max.attempts</name><value>4</value></property>
<property><name>mapred.job.tracker</name><value>localhost:53802</value></property>
<property><name>dfs.namenode.decommission.interval</name><value>3</value></property>
<property><name>hbase.defaults.for.version.skip</name><value>false</value></property>
<property><name>dfs.name.edits.dir</name><value>${dfs.name.dir}</value></property>
<property><name>hbase.server.versionfile.writeattempts</name><value>3</value></property>
<property><name>io.mapfile.bloom.error.rate</name><value>0.005</value></property>
<property><name>mapred.tasktracker.expiry.interval</name><value>600000</value></property>
<property><name>hbase.regionserver.info.bindAddress</name><value>0.0.0.0</value></property>
<property><name>io.sort.record.percent</name><value>0.05</value></property>
<property><name>dfs.safemode.threshold.pct</name><value>0.999f</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.active</name><value>false</value></property>
<property><name>dfs.name.dir</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/dfscluster_aad504e8-cd3f-411c-aea3-9b5473a19e07/dfs/name1,/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/dfscluster_aad504e8-cd3f-411c-aea3-9b5473a19e07/dfs/name2</value></property>
<property><name>mapreduce.job.acl-modify-job</name><value> </value></property>
<property><name>fs.checkpoint.period</name><value>3600</value></property>
<property><name>io.skip.checksum.errors</name><value>false</value></property>
<property><name>hbase.zookeeper.peerport</name><value>2888</value></property>
<property><name>dfs.datanode.handler.count</name><value>3</value></property>
<property><name>hbase.master.port</name><value>60000</value></property>
<property><name>dfs.namenode.decommission.nodes.per.interval</name><value>5</value></property>
<property><name>mapred.temp.dir</name><value>${hadoop.tmp.dir}/mapred/temp</value></property>
<property><name>mapred.mapoutput.key.class</name><value>org.apache.hadoop.hbase.io.ImmutableBytesWritable</value></property>
<property><name>hadoop.native.lib</name><value>true</value></property>
<property><name>mapreduce.job.counters.limit</name><value>120</value></property>
<property><name>hbase.client.keyvalue.maxsize</name><value>10485760</value></property>
<property><name>fs.webhdfs.impl</name><value>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</value></property>
<property><name>dfs.datanode.ipc.address</name><value>127.0.0.1:0</value></property>
<property><name>mapred.working.dir</name><value>/development/workspaces/p13n-adds/datacube/target/test-data/3c43d028-0b7e-40fc-8d2e-031443c33d24/mapred-working-dir</value></property>
<property><name>mapred.job.reduce.input.buffer.percent</name><value>0.0</value></property>
<property><name>hbase.hregion.memstore.block.multiplier</name><value>2</value></property>
<property><name>hbase.server.thread.wakefrequency</name><value>10000</value></property>
</configuration>